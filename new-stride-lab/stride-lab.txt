                 COMP 40 Lab: Striding Through Memory
        (for groups of two -- work with your locality partner)



+--------------------------------------------------------+
|Keeper of the record: wgoldm03                          |
|--------------------------------------------------------|
|Lab partner:   mbotta01                                 |
+--------------------------------------------------------+


Please edit this document to include your answers to the questions
below, and use the submit40-lab-strides script to submit your
answers. 

Read these questions before you start doing the lab experiments, and
use these questions to guide your choice of test cases. Remember, the
particular tests listed in the instructions are just hints for getting
you started: you should run any experiments that you think will help
you answer these questions or understand how the cache works.

Don't worry if you aren't sure of an answer to a given quesetion.
The goal here is to start teaching you to do what cache
designers do: think step-by-step through what happens in a cache as
a program runs, use actual simulations to determine which designs
perform best on which applications, and extract general
principles of cache design from the results of these simulations.

FOR THESE FIRST FEW QUESTIONS, ASSUME A DIRECT MAPPED CACHE (the
-assoc 1 setting for testcachesim, which is the default).

Cache Size
----------

Q1a: If you know the block size in bytes for a cache and the number of
     lines in the cache, what will be the total size of the cache in
     bytes? 


Cache size = block size × number of lines




Q1b: For testcachesim, describe in detail how performance changes as
     the size of the cache gets larger, presuming the size of the
     test array remains the same?  



Performance improves as cache grows, since more of the array fits and miss 
rate drops. Once the whole working set fits, further growth gives little 
benefit.




Q1c. Is there a point beyond which performance stops improving as
     cache size increases? Why?



Yes. Past the working-set size, more cache doesn’t help. Misses are mostly 
compulsory.



Q1d. Sometimes performance is excellent (that is, the cache gives us a
     very good speed up) but then making the test array just a little
     bigger reduces performance dramatically. Why?


A small array increase can trigger conflicts in direct-mapped caches 
(two addresses map to same line), causing sudden performance drops.
Each element adds 8 accesses (write + read, repeated 4×).



Block sizes
-----------

In this section, assume that the total size of the cache we can build
is fixed, but that we get to make choices as to whether we have
fewer lines with bigger blocks, or more lines with smaller blocks.

Q2.  Are bigger blocks always better? Worse? Assuming the total size
     of the cache remains the same, and for an application like
     testcachesim, which block size is best?


Bigger blocks help with sequential access (spatial locality) but hurt with high 
stride or conflicts (fewer lines). Best block size depends on access pattern.




Writing data
------------

Q3.  Reread the part of the instructions that explains the
     "Reads_for_writes" count in your cache statistics. Is there a
     value of the block size that will make "Reads_for_writes" zero?
     If you understand this, then you understand a lot about how
     "write-back" caches work.



Reads_for_writes = 0 only if every write hits a block already in cache (e.g., 
very large blocks or whole working set resident). Otherwise a read is needed 
before a write.




Q4.  Explain why, for applications that update memory repeatedly, a cache that
     performs better may finish with more dirty blocks than a cache
     that does not perform well on the same application.


A good cache keeps updated blocks resident which means more dirty blocks at the 
end. A poor cache evicts them early which means fewer dirty blocks, but worse 
performance.



=================================================================
                     Associative caches
=================================================================

Q5.  Can you describe a situation in which a fully associative cache
     will outperform a direct-mapped cache?


Fully associative caches win when multiple hot blocks map to the same index in 
a direct-mapped cache, avoiding conflict misses.



Submit this file using script

       submit40-lab-strides
